{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5156926-b86a-4e95-aeda-2cf8199463af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import torch\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "class _Preprocessing():\n",
    "    \n",
    "    def __init__(self, data_name, data_type, time_window, forecasting_term, train_ratio = 0.7):  \n",
    "        \n",
    "        self.dt = pd.read_csv(data_name, usecols=[1]).iloc[:8000,:].clip(lower=0).astype('float32')\n",
    "        self.data_type = data_type \n",
    "        self.time_window = time_window\n",
    "        self.forecasting_term = forecasting_term\n",
    "        self.train_ratio = train_ratio\n",
    "        self.scaler = MinMaxScaler()\n",
    "    \n",
    "    def preprocessing(self):\n",
    "        \n",
    "        # Data Normalization\n",
    "        self.scaler.fit_transform(self.dt)\n",
    "                \n",
    "        # Train Test Seperation\n",
    "        len_train = int(len(self.dt)*self.train_ratio)\n",
    "        \n",
    "        train = self.dt.iloc[:len_train,:]\n",
    "        test = self.dt.iloc[len_train:,:]\n",
    "        \n",
    "        trainX, testX, trainY, testY = [], [], [], []\n",
    "        \n",
    "        for i in range(self.time_window, len(train)-29):\n",
    "            trainX.append(train.iloc[(i-self.time_window):i-self.time_window + 10,:].values)\n",
    "            trainY.append(train.iloc[i-self.time_window + 10:i-self.time_window + 10+20,:].values)\n",
    "\n",
    "        for i in range(self.time_window, len(test)-10-19):\n",
    "            testX.append(test.iloc[(i-self.time_window):i-self.time_window+10,:].values)\n",
    "            testY.append(test.iloc[i-self.time_window + 10:i-self.time_window + 10+20,:].values)\n",
    "\n",
    "\n",
    "        trainX = np.array(trainX)\n",
    "        trainY = np.array(trainY)\n",
    "\n",
    "        trainY = trainY.reshape(trainY.shape[0] , trainY.shape[1])\n",
    "        testX = np.array(testX)        \n",
    "        testY = np.array(testY)        \n",
    "        testY = testY.reshape(testY.shape[0] , testY.shape[1])\n",
    "        \n",
    "        # print(trainX[:10])\n",
    "        # print(trainY[:10])\n",
    "        return trainX, trainY, testX, testY, self.scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da125c7-ee17-4631-8dcc-7b4bb5d58a55",
   "metadata": {},
   "source": [
    "## CRU Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82eb0069-af6f-45de-9df8-168eb2b7647f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\techno\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.seasonal import STL\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "class _CRUCell(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, in_dim, hid_dim, bias=True):\n",
    "        super(_CRUCell, self).__init__()\n",
    "        \n",
    "        self.in_dim = in_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.bias = bias\n",
    "        \n",
    "        self.wx_t = tf.keras.layers.Dense(hid_dim*3, activation=None, use_bias=True)\n",
    "        self.wx_s = tf.keras.layers.Dense(hid_dim*3, activation=None, use_bias=True)\n",
    "        self.wx_r = tf.keras.layers.Dense(hid_dim, activation=None, use_bias=True)\n",
    "        \n",
    "        self.wh_t = tf.keras.layers.Dense(hid_dim*3, activation=None, use_bias=True)\n",
    "        self.wh_s = tf.keras.layers.Dense(hid_dim*3, activation=None, use_bias=True)\n",
    "        self.wh_r = tf.keras.layers.Dense(hid_dim, activation=None, use_bias=True)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "            \n",
    "\n",
    "    def __call__(self, x, hid_state = None):\n",
    "        \n",
    "        lamda = 0.5\n",
    "        x_t, x_s, x_r = self.ts_decompose(x)\n",
    "        \n",
    "        if hid_state is None:\n",
    "            hid_state = np.zeros((3, x.size(1), self.hid_dim))\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            \n",
    "            x_t = self.wx_t(x_t)\n",
    "            x_s = self.wx_s(x_s)\n",
    "            x_r = self.wx_r(x_r)\n",
    "            # print(x_t.shape)\n",
    "            h_t = self.wh_t(hid_state[0,:,:])\n",
    "            h_s = self.wh_s(hid_state[1,:,:])\n",
    "            # print(h_t.shape)\n",
    "        \n",
    "        x_autocor_t, x_cor_t, x_new_t = np.split(x_t, 3, axis=1)\n",
    "        x_autocor_s, x_cor_s, x_new_s = np.split(x_s, 3, axis=1)\n",
    "        h_autocor_t, h_cor_t, h_new_t = np.split(h_t, 3, axis=1)\n",
    "        h_autocor_s, h_cor_s, h_new_s = np.split(h_s, 3, axis=1)\n",
    "\n",
    "        autocor_t = tf.nn.sigmoid(x_autocor_t + h_autocor_t)\n",
    "        autocor_s = tf.nn.sigmoid(x_autocor_s + h_autocor_s)\n",
    "        \n",
    "        cor_t = tf.nn.sigmoid(x_cor_t + h_cor_s)\n",
    "        cor_s = tf.nn.sigmoid(x_cor_s + h_cor_t)\n",
    "        \n",
    "        new_t = lamda*np.tanh(x_new_t + (autocor_t * h_new_t)) + (1-lamda)*np.tanh(x_new_t + (cor_t * h_new_s))\n",
    "        new_s = lamda*np.tanh(x_new_s + (autocor_s * h_new_s)) + (1-lamda)*np.tanh(x_new_s + (cor_s * h_new_t))\n",
    "        \n",
    "       \n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            hid_state[0,:,:] = new_t\n",
    "            hid_state[1,:,:] = new_s\n",
    "            hid_state[2,:,:] = np.tanh(x_r)\n",
    "        \n",
    "        return hid_state\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        std = 1.0 / np.sqrt(self.hid_dim)\n",
    "        \n",
    "        for w in self.get_parameters():\n",
    "            w.data.uniform_(-std, std)\n",
    "    def get_parameters(self):\n",
    "        # Return the trainable parameters of the model\n",
    "        return self.trainable_variables\n",
    "        \n",
    "    def ts_decompose(self, x):\n",
    "        \n",
    "        x = pd.DataFrame(x)\n",
    "        \n",
    "        dates = pd.date_range('1990-01-01', periods = len(x), freq='D')\n",
    "        x.index = dates\n",
    "        trend = []\n",
    "        seasonal = []\n",
    "        resid = []\n",
    "        for i in range(len(x.columns)):\n",
    "            stl = STL(x[i])\n",
    "            res = stl.fit()\n",
    "            trend.append(res.trend.values)\n",
    "            seasonal.append(res.seasonal.values)\n",
    "            resid.append(res.resid.values)\n",
    "\n",
    "        trend = np.array(trend)\n",
    "        seasonal = np.array(seasonal)\n",
    "        resid = np.array(resid)\n",
    "\n",
    "        \n",
    "        trend = np.transpose(np.array(trend))\n",
    "        seasonal = np.transpose(np.array(seasonal))\n",
    "        resid = np.transpose(np.array(resid))\n",
    "        \n",
    "        return trend, seasonal, resid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabb8ad3-0434-47c8-866a-c52d62c726fb",
   "metadata": {},
   "source": [
    "## CRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "366071d3-6772-43ad-8a98-dcc401be67b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class _CRU(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, in_dim, hid_dim, out_dim, num_layers, bias = True):\n",
    "        super(_CRU, self).__init__()\n",
    "        \n",
    "        self.in_dim = in_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.bias = bias\n",
    "        self.out_dim = out_dim\n",
    "        \n",
    "        self.cell_list =  []\n",
    "        self.cell_list.append(_CRUCell(self.in_dim,\n",
    "                                               self.hid_dim, \n",
    "                                               self.bias))\n",
    "        for l in range(1, self.num_layers): ## will not be executed \n",
    "            self.cell_list.append(_CRUCell(self.hid_dim,\n",
    "                                                   self.hid_dim,\n",
    "                                                   self.bias))\n",
    "\n",
    "        self.fc = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(out_dim, input_shape=(hid_dim,)),\n",
    "            tf.keras.layers.ELU()\n",
    "            ])\n",
    "            \n",
    "    def get_parameters(self):\n",
    "        # Return the trainable parameters of the model\n",
    "        return self.trainable_variables\n",
    "    \n",
    "    def __call__(self, input, hid_state=None):\n",
    "        # print(\"today is saurav kapadiya's \",type(input))\n",
    "        if hid_state is None:\n",
    "            hid_state = np.zeros((self.num_layers, 3, input.shape[0], self.hid_dim))\n",
    "        else:\n",
    "            hid_state = hid_state\n",
    "\n",
    "        outs = []\n",
    "\n",
    "        hidden = list()\n",
    "        for layer in range(self.num_layers):\n",
    "            hidden.append(hid_state[layer,:, :, :])\n",
    "        \n",
    "        for t in range(input.shape[1]):\n",
    "\n",
    "            for layer in range(self.num_layers):\n",
    "\n",
    "                if layer == 0:\n",
    "                    hid_layer = self.cell_list[layer](input[:, t, :], hidden[layer])\n",
    "                else:\n",
    "                    hid_layer = self.cell_list[layer](hidden[layer - 1],hidden[layer])\n",
    "                \n",
    "                hidden[layer] = hid_layer\n",
    "                \n",
    "            outs.append(hid_layer)\n",
    "       \n",
    "        feature = np.mean(outs[-1],axis=1)\n",
    "    \n",
    "        out = np.sum(outs[-1],axis=0)\n",
    "        out = np.array(out)\n",
    "\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out, feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5084d64a-eef4-40b5-a3c4-ec6413a26103",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e66e325-4c89-40b7-b338-f062cc529733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(pred, actual):\n",
    "    error = np.subtract(pred, actual)\n",
    "    sqerror= np.sum(np.square(error))/actual.shape[0]\n",
    "    return np.sqrt(sqerror)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4574ecd2-d21b-468e-982e-549950bdc34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "\n",
    "class ModelTrain():\n",
    "    \n",
    "    def __init__(self, data_name, data_type, time_window, forecasting_term):\n",
    "\n",
    "        self.in_dim = time_window\n",
    "        pre = _Preprocessing(data_name, data_type, time_window, forecasting_term)\n",
    "        self.trainX, self.trainY, self.testX, self.testY, self.scaler = pre.preprocessing()\n",
    "        # print(type(self.trainX))\n",
    "        \n",
    "                    \n",
    "    def _fit(self, hid_dim, out_dim, num_layers, epoch):\n",
    "        \n",
    "        model = _CRU(self.in_dim, hid_dim, out_dim, num_layers)\n",
    "        # Instantiate an optimizer.\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4)\n",
    "        # Instantiate a loss function.\n",
    "        mse = tf.keras.losses.MeanSquaredError()\n",
    "        \n",
    "        for e in range(epoch):\n",
    "            # print(\"start of epoch #\",e)\n",
    "    \n",
    "            with tf.GradientTape() as tape:\n",
    "                trainPredict, _ = model(self.trainX)\n",
    "                loss = mse(self.trainY, trainPredict)\n",
    "\n",
    "                # Use the gradient tape to automatically retrieve\n",
    "                # the gradients of the trainable variables with respect to the loss.\n",
    "            grads = tape.gradient(loss , model.trainable_weights,unconnected_gradients=tf.UnconnectedGradients.ZERO)\n",
    "\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        \n",
    "            if (e+1) % 100 == 0:\n",
    "                with tf.GradientTape() as tape:\n",
    "                    testPred,_ = model(self.testX)\n",
    "                    testPred =   np.array(testPred)\n",
    "                    trainPredict = np.array(trainPredict)\n",
    "                    # print(self.trainY[15:20])\n",
    "                    testdata = self.testY\n",
    "                    traindata = self.trainY\n",
    "\n",
    "                    \n",
    "                    trainPredict = self.scaler.inverse_transform(trainPredict)\n",
    "                    testPred = self.scaler.inverse_transform(testPred)\n",
    "                    testdata = self.scaler.inverse_transform(testdata)\n",
    "                    traindata = self.scaler.inverse_transform(traindata)\n",
    "\n",
    "                    test_mape = np.mean(abs((np.array(testPred)-np.array(testdata))/np.array(testPred)))*100\n",
    "                    test_rmse = rmse(testPred, testdata)\n",
    "                    train_rmse = rmse(trainPredict, traindata)\n",
    "                print('[Epoch: {}/{}] [Train RMSE: {}] [Test RMSE: {}] [Test MAPE: {}]'.format(\n",
    "                    e+1, epoch, str(train_rmse)[:6], str(test_rmse)[:6], str(test_mape)[:6]))\n",
    "                # print(trainY.shape)\n",
    "        \n",
    "        return model,traindata,trainPredict,testdata,testPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95ea8cf2-5ad0-4373-ba7d-eca1f92dea44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_name = 'output2.csv'\n",
    "data_type = 'univariate'\n",
    "\n",
    "time_window = 1\n",
    "forecasting_term = 1\n",
    "    \n",
    "model = ModelTrain(data_name, data_type, time_window, forecasting_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1df21e-a13b-4105-88b2-20f732a22aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\techno\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "[Epoch: 100/300] [Train RMSE: 28524.] [Test RMSE: 35614.] [Test MAPE: 17273.]\n"
     ]
    }
   ],
   "source": [
    "hid_dim = 25\n",
    "out_dim = 20\n",
    "num_layers = 1\n",
    "epoch = 300\n",
    "\n",
    "m,trainY,trainPredict,testY,testPred = model._fit(hid_dim, out_dim, num_layers, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a930ecff-545f-4170-9376-db8a3bbca2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_Predict_Test=testPred\n",
    "Best_Predict_Train=trainPredict\n",
    "\n",
    "x_data=np.linspace(0,trainY.shape[0], num=trainY.shape[0])\n",
    "# x_data.shape\n",
    "plt.plot(x_data[360:450], trainPredict[360:450,19], label='actual',color='r')\n",
    "plt.plot(x_data[360:450], trainY[360:450,19], label='predicted')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48792a2-7309-4d86-8f8d-c3a617d39fca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
